---
title: Autonomous Mobile Robot
description: An academic project involving the development of a mobile robot that can autonomously navigate and search for objects within an arena. 
layout: post
---

WORK IN PROGRESS

This project uses an Alphabot2 kit from Waveshare with a Raspberry Pi 4 Model B as the controller. 


The development of this project is split into a 4 different parts:
1. Simultaneous Localization and Mapping (SLAM)
2. Object Detection and Recognition using a Convolutional Neural Network (CNN)  <---- Currently here
3. Path Plannning 
4. Integration

# SLAM 
SLAM was done by manually driving the robot around the arena (3m x 3m in size) to look for ArUco markers and using them to determine the position of the robot on a map.

To achieve this, an Extended Kalman Filter and ArUco marker detector was implemented in Python.

Example of arena and ArUco markers:
![image](/assets/aruco.jpg)

# Object Detection and Recognition using a CNN
Since the end goal of this robot is to autonomously detect objects (fruits) placed around the arena, at this stage we train a CNN for object detection and recognition using YOLO as the model. 

The dataset was generated by taking pictures of the fruits and arena using the robot's camera and then superimposing them onto each other with randomized placements and sizes. 

Example of an image from the generated dataset:
![image](/assets/capsicum.png)